#!/usr/bin/env python
import os
import md5
import time
import magic
import requests
import argparse


class Malware:
    def __init__(self, path, timeout, verbose):
        self.path = path
        self.timeout = timeout
        self.verbose = verbose
        self.magic = magic.open(magic.MAGIC_NONE)
        self.magic.load()
        try:os.makedirs(path)
        except OSError:pass
        if not os.path.exists('%s/log' % path):
            f = open('%s/log' % path, 'w+')
            f.close()

    def scrape(self):
        #try:self._save(list(self._malwaredl()), 'www.malwaredomainlist.com')
        #except: pass
        #try:self._save(list(self._minotaur()), 'www.minotauranalysis.com')
        #except: pass
        #try:self._save(list(self._vxvault()), 'www.vxvault.siri.urz.net')
        #except: pass
        try:self._save(list(self._malcode()), 'www.malcOde.com')
        except: pass
        #try:self._save(list(self._malwarebl()), 'www.malwareblacklist.com')
        #except: pass
        #try:self._save(list(self._sacour()), 'www.sacour.cn')
        #except: pass

    def _save(self, items, url):
        l = open('%s/log' % self.path, 'a')
        print 'found %s items on %s' % (len(items), url)
        for item in items:
            try:
                try:download = requests.get(item['link'], timeout=self.timeout)
                except: continue
                mhash = md5.new(download.content).hexdigest()
                ftype = self.magic.buffer(download.content).split(' ')[0].lower()
                if self.verbose is True:
                    print '[DOWNLOADED] %s' % item['link'][:60]
                description = item['description'].replace(' ', '_').replace('.', '_')
                description = description.replace(':', '_').replace('/', '_')
                description = '_'.join(description.split('_')[:2])
                dpath = '%s/%s/%s' % (self.path, ftype, description)
                if not os.path.exists(dpath):
                    os.makedirs(dpath)
                if not os.path.exists('%s/%s' % (dpath, mhash)):
                        f = open('%s/%s' % (dpath, mhash), 'w+')
                        f.write(download.content)
                        f.close()
                        l.write('%s,%s,%s,%s,%s\n' % (
                            item['date'], item['link'], item['country'], mhash, description))
            except Exception as e: print e
        l.close()

    def _malwaredl(self):
        http = requests.get('http://www.malwaredomainlist.com/hostslist/mdl.xml', timeout=self.timeout)
        for item in http.content.split('<title>'):
            try:
                link = item.split('Host: ')[1].split(',')[0]
                if link is '-':
                    link =  item.split('IP address: ')[1].split(',')[0]
                description = item.split('Description: ')[1].split('</description>')[0]
                country = item.split('Country: ')[1].split(',')[0]
                date = item.split(' (')[1].split(')</title>')[0]
                yield {'link':'http://%s' % link,
                       'description':description,
                       'country':country,
                       'date':date}
            except IndexError: pass
            except Exception as e: print '[Error] %s' % e


    def _minotaur(self):
        pass
        ##### still broken #####
        #'http://minotauranalysis.com/malwarelist-urls.aspx'

    def _vxvault(self):
        http = requests.get('http://vxvault.siri-urz.net/URL_List.php', timeout=self.timeout)
        for line in http.content.split('\n'):
            if line.startswith('http://'):
                yield {'link':line,
                    'description':'unkown',
                    'country':'unkown',
                    'date':time.strftime('%c')}

    def _malcode(self):
        http = requests.get('http://malc0de.com/rss', timeout=self.timeout)
        for item in http.content.split('<title>'):
            try:
                link = item.split('URL: ')[1].split(',')[0]
                country = item.split('Country: ')[1].split(',')[0]
                yield {'link':'http://%s' % link,
                       'description':'unknown',
                       'country':country,
                       'date':time.strftime('%c')}
            except IndexError: pass
            except Exception as e: print '[Error] %s' % e

    def _malwarebl(self):
        http = requests.get('http://www.malwareblacklist.com/showMDL.php')
        req = http.content.split('type="text/javascript">show_results(\'')[1]
        req = req.split("');")[0]
        http = requests.get('http://www.malwareblacklist.com/showAllMalwareURL.php?%s' % req)
        for item in http.content.split('<tr class=Odd>')[1:-1]:
            for i in item.split('<tr class=Even>'):
                try:
                    link = i.split("; padding-right:5px;'> ")[1].split('<td class')[0]
                    if link.startswith("<span style='font-size:10px'>"):
                        link = ''.join(link[29:-7].split('<wbr>'))
                    country = i.split(" alt='")[1].split("' title")[0]
                    yield {'link':'http://%s' % link,
                           'description':'unknown',
                           'country':country,
                           'date':time.strftime('%c')}
                except IndexError: pass
                except Exception as e: print '[Error] %s' % e

    def _sacour(self):
        pass
        ##### still broken #####
        #'http://www.sacour.cn/showmal.asp?month=%d&year=%d'


if __name__ == '__main__':
    parse = argparse.ArgumentParser()
    parse.add_argument('path', help='dir path to save output')
    parse.add_argument('-v', help='verbose', action='store_true')
    parse.add_argument('-t', metavar=('time'),
        help='timeout (DEFAULT: 5)', default=5)
    args = parse.parse_args()
    malware = Malware(args.path, args.t, args.v)
    malware.scrape()

